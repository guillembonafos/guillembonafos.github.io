@misc{bonafosDetectionClassificationVocal2023a,
  title = {Detection and Classification of Vocal Productions in Large Scale Audio Recordings},
  author = {Bonafos, Guillem and Pudlo, Pierre and Freyermuth, Jean-Marc and Legou, Thierry and Fagot, Jo{\"e}l and Tron{\c c}on, Samuel and Rey, Arnaud},
  year = {2023},
  month = aug,
  number = {arXiv:2302.07640},
  eprint = {2302.07640},
  primaryclass = {cs, eess, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2302.07640},
  urldate = {2023-11-14},
  abstract = {We propose an automatic data processing pipeline to extract vocal productions from large-scale natural audio recordings and classify these vocal productions. The pipeline is based on a deep neural network and adresses both issues simultaneously. Though a series of computationel steps (windowing, creation of a noise class, data augmentation, re-sampling, transfer learning, Bayesian optimisation), it automatically trains a neural network without requiring a large sample of labeled data and important computing resources. Our end-to-end methodology can handle noisy recordings made under different recording conditions. We test it on two different natural audio data sets, one from a group of Guinea baboons recorded from a primate research center and one from human babies recorded at home. The pipeline trains a model on 72 and 77 minutes of labeled audio recordings, with an accuracy of 94.58\% and 99.76\%. It is then used to process 443 and 174 hours of natural continuous recordings and it creates two new databases of 38.8 and 35.2 hours, respectively. We discuss the strengths and limitations of this approach that can be applied to any massive audio recording.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing,Statistics - Applications},
  file = {/home/guillhem/Zotero/storage/VZEMTAPT/Bonafos et al_2023_Detection and classification of vocal productions in large scale audio.pdf;/home/guillhem/Zotero/storage/F9A3F4SY/2302.html}
}

@misc{bonafosFrenchVowels2023,
  title = {{French vowels}},
  author = {Bonafos, Guillem and Freyermuth, Jean-Marc and Pudlo, Pierre and Tron{\c c}on, Samuel and Rey, Arnaud},
  year = {2023},
  month = may,
  publisher = {{Zenodo}},
  doi = {10.5281/zenodo.7961904},
  urldate = {2023-05-23},
  abstract = {Dataset of audio recordings. 20 adult French speakers were recorded saying 8 vowels, under 7 conditions, 10 times each.},
  langid = {fra},
  keywords = {audio,french,speech,vowel},
  file = {/home/guillhem/Zotero/storage/643HFUZE/7961904.html}
}

@misc{bonafosGuineaBaboonVocalisations2023,
  title = {Guinea Baboon Vocalisations Dataset Automatically Extracted from Natural Audio Recordings},
  author = {Bonafos, Guillem and Pudlo, Pierre and Freyermuth, Jean-Marc and Legou, Thierry and Fagot, Jo{\^e}l and Tron{\c c}on, Samuel and Rey, Arnaud},
  year = {2023},
  month = may,
  publisher = {{Zenodo}},
  doi = {10.5281/zenodo.7963124},
  urldate = {2023-05-23},
  abstract = {The data collection process consisted of continuously recording an enclosure of Guinea baboons for one month. They live in semi-liberty at the CNRS primatology centre in Rousset. A microphone was placed nearby to record the sounds produced by the group without the presence of a human. A neural network was used on these large and noisy audio recordings, following the method of Bonafos et al. (2023). The neural network automatically detected segments in the data stream when the baboons produced vocalisations. The dataset consists of one second to several minute wav files of automatically detected segments of vocalisations produced in semi-natural environments. The dataset thus provides a new set of baboon vocalisations produced at all times of the day, without the presence of a recording human. It can be used to learn more about the vocal productions of non-human primates, their distribution over the day, their frequency, and their heterogeneity. In addition to the analysis of animal communication, the dataset can also be used as a learning base for sound recognition models.},
  keywords = {baboon,bioacoustics,event detection,natural audio recordings,sound,vocalisation},
  file = {/home/guillhem/Zotero/storage/WZBBLS52/7963124.html}
}

@misc{bonafosTopologicalDataAnalysis2023,
  title = {Topological Data Analysis of Human Vowels: {{Persistent}} Homologies across Representation Spaces},
  shorttitle = {Topological Data Analysis of Human Vowels},
  author = {Bonafos, Guillem and Freyermuth, Jean-Marc and Pudlo, Pierre and Tron{\c c}on, Samuel and Rey, Arnaud},
  year = {2023},
  month = oct,
  number = {arXiv:2310.06508},
  eprint = {2310.06508},
  primaryclass = {cs, eess, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2310.06508},
  urldate = {2023-11-14},
  abstract = {Topological Data Analysis (TDA) has been successfully used for various tasks in signal/image processing, from visualization to supervised/unsupervised classification. Often, topological characteristics are obtained from persistent homology theory. The standard TDA pipeline starts from the raw signal data or a representation of it. Then, it consists in building a multiscale topological structure on the top of the data using a pre-specified filtration, and finally to compute the topological signature to be further exploited. The commonly used topological signature is a persistent diagram (or transformations of it). Current research discusses the consequences of the many ways to exploit topological signatures, much less often the choice of the filtration, but to the best of our knowledge, the choice of the representation of a signal has not been the subject of any study yet. This paper attempts to provide some answers on the latter problem. To this end, we collected real audio data and built a comparative study to assess the quality of the discriminant information of the topological signatures extracted from three different representation spaces. Each audio signal is represented as i) an embedding of observed data in a higher dimensional space using Taken's representation, ii) a spectrogram viewed as a surface in a 3D ambient space, iii) the set of spectrogram's zeroes. From vowel audio recordings, we use topological signature for three prediction problems: speaker gender, vowel type, and individual. We show that topologically-augmented random forest improves the Out-of-Bag Error (OOB) over solely based Mel-Frequency Cepstral Coefficients (MFCC) for the last two problems. Our results also suggest that the topological information extracted from different signal representations is complementary, and that spectrogram's zeros offers the best improvement for gender prediction.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing,Statistics - Applications,Statistics - Machine Learning},
  file = {/home/guillhem/Zotero/storage/BN9KNL8U/Bonafos et al_2023_Topological data analysis of human vowels.pdf;/home/guillhem/Zotero/storage/7TZMMFL2/2310.html}
}

@article{reyDetectionRegularitiesRandom2020,
  title = {Detection of Regularities in a Random Environment},
  author = {Rey, Arnaud and Bogaerts, Louisa and Tosatto, Laure and Bonafos, Guillem and Franco, Ana and Favre, Benoit},
  year = {2020},
  month = jul,
  journal = {Quarterly Journal of Experimental Psychology},
  pages = {174702182094135},
  issn = {1747-0218, 1747-0226},
  doi = {10.1177/1747021820941356},
  urldate = {2020-07-29},
  abstract = {Regularity detection, or statistical learning, is regarded as a fundamental component of our cognitive system. To test the ability of human participants to detect regularity in a more ecological situation (i.e., mixed with random information), we used a simple letter-naming paradigm in which participants were instructed to name single letters presented one at a time on a computer screen. The regularity consisted of a triplet of letters that were systematically presented in that order. Participants were not told about the presence of this regularity. A variable number of random letters were presented between two repetitions of the regular triplet, making this paradigm similar to a Hebb repetition task. Hence, in this Hebb-naming task, we predicted that if any learning of the triplet occurred, naming times for the predictable letters in the triplet would decrease as the number of triplet repetitions increased. Surprisingly, across four experiments, detection of the regularity only occurred under very specific experimental conditions and was far from a trivial task. Our study provides new evidence regarding the limits of statistical learning and the critical role of contextual information in the detection (or not) of repeated patterns.},
  copyright = {All rights reserved},
  langid = {english},
  file = {/home/guillhem/Zotero/storage/7GWUP67Y/Rey et al. - 2020 - Detection of regularities in a random environment.pdf}
}

@article{reyLearningHigherOrder2022,
  title = {Learning {{Higher}}-{{Order Transitional Probabilities}} in {{Nonhuman Primates}}},
  author = {Rey, Arnaud and Fagot, Jo{\"e}l and Mathy, Fabien and Lazartigues, Laura and Tosatto, Laure and Bonafos, Guillem and Freyermuth, Jean-Marc and Lavigne, Fr{\'e}d{\'e}ric},
  year = {2022},
  month = apr,
  journal = {Cognitive Science},
  volume = {46},
  number = {4},
  issn = {0364-0213, 1551-6709},
  doi = {10.1111/cogs.13121},
  urldate = {2022-04-05},
  abstract = {The extraction of cooccurrences between two events, A and B, is a central learning mechanism shared by all species capable of associative learning. Formally, the cooccurrence of events A and B appearing in a sequence is measured by the transitional probability (TP) between these events, and it corresponds to the probability of the second stimulus given the first (i.e., p(B|A)). In the present study, nonhuman primates (Guinea baboons, Papio papio) were exposed to a serial version of the XOR (i.e., exclusive-OR), in which they had to process sequences of three stimuli: A, B, and C. In this manipulation, first-order TPs (i.e., AB and BC) were uninformative due to their transitional probabilities being equal to .5 (i.e., p(B|A) = p(C|B) = .5), while second-order TPs were fully predictive of the upcoming stimulus (i.e., p(C|AB) = 1). In Experiment 1, we found that baboons were able to learn second-order TPs, while no learning occurred on first-order TPs. In Experiment 2, this pattern of results was replicated, and a final test ruled out an alternative interpretation in terms of proximity to the reward. These results indicate that a nonhuman primate species can learn a nonlinearly separable problem such as the XOR. They also provide fine-grained empirical data to test models of statistical learning on the interaction between the learning of different orders of TPs. Recent bioinspired models of associative learning are also introduced as promising alternatives to the modeling of statistical learning mechanisms.},
  copyright = {All rights reserved},
  langid = {english},
  file = {/home/guillhem/Zotero/storage/L3GJSJSA/Rey et al. - 2022 - Learning Higher‐Order Transitional Probabilities i.pdf}
}

@article{tosattoDetectingNonadjacentDependencies2022,
  title = {Detecting Non-Adjacent Dependencies Is the Exception Rather than the Rule},
  author = {Tosatto, Laure and Bonafos, Guillem and Melmi, Jean-Baptiste and Rey, Arnaud},
  editor = {Kempe, Vera},
  year = {2022},
  month = jul,
  journal = {PLOS ONE},
  volume = {17},
  number = {7},
  pages = {e0270580},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0270580},
  urldate = {2022-07-15},
  abstract = {Statistical learning refers to our sensitivity to the distributional properties of our environment. Humans have been shown to readily detect the dependency relationship of events that occur adjacently in a stream of stimuli but processing non-adjacent dependencies (NADs) appears more challenging. In the present study, we tested the ability of human participants to detect NADs in a new Hebb-naming task that has been proposed recently to study regularity detection in a noisy environment. In three experiments, we found that most participants did not manage to extract NADs. These results suggest that the ability to learn NADs in noise is the exception rather than the rule. They provide new information about the limits of statistical learning mechanisms.},
  copyright = {All rights reserved},
  langid = {english},
  file = {/home/guillhem/Zotero/storage/EUTL3DKE/file.pdf}
}
